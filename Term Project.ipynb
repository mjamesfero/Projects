{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Project\n",
    "## Imports\n",
    "I like to start off all notebooks with a cell at the beginning that has every used import so that I don't need to check all over to ensure that I've met all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Here I'm using the data from the exoplanet catalogue and the Week 4 notebook for this project. This first cell is just to single out which data I'm using and cleaning it up.\n",
    "\n",
    "Note that in the original notebook, some features were manually selected to focus on. Here, we're replacing that with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/blue/ast4930/share/phl_exoplanet_catalog.csv', sep = ',')\n",
    "#Making a new pandas df that combines both 'conservative' and 'optmistic' hability labels into one category\n",
    "data_original = df.drop('P_HABITABLE', axis = 1)\n",
    "#Combining the two habitability types\n",
    "data_original['P_HABITABLE'] = (np.logical_or((df.P_HABITABLE == 1) , (df.P_HABITABLE == 2)))\n",
    "#Making the data into integer format\n",
    "data_original['P_HABITABLE'] = data_original['P_HABITABLE'].astype(int) \n",
    "\n",
    "#Sectioning off the hability labels specifically\n",
    "targets = data_original.P_HABITABLE\n",
    "\n",
    "#Getting rid of missing data\n",
    "data_original = bindf.dropna(axis = 0) \n",
    "data_original = data_original[(np.abs(stats.zscore(data_original)) < 5).all(axis=1)] \n",
    "#Fixing index issues caused by the above\n",
    "targets = targets[data_original.index]\n",
    "data_original = data_original.reset_index(drop=True)\n",
    "targets = targets.reset_index(drop=True)\n",
    "\n",
    "#Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_original, targets, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a look at our data before starting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "cmap = colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "a = plt.scatter(data_original['S_MASS'], data_original['P_PERIOD'], marker = 'o',\\\n",
    "            c = targets, s = 20, cmap=cmap, label = 'Test')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "a.set_facecolor('none')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "\n",
    "plt.legend(handles=[magentapatch, bluepatch],\\\n",
    "           loc = 'lower right', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are split *before* the scaling is applied. Since PCA needs standard scaling, we will be doing that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = StandardScaler().fit_transform(X_train)\n",
    "X_test_s = StandardScaler().fit(X_train).transform(X_test)\n",
    "#applying PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "X_pca = pca.fit_transform(X_train_s)\n",
    "X_test_p = pca.fit(X_train_s).transform(X_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "First, we will see how the DT fares in classifying our exoplanets as habitable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': np.arange(10)+1}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=21), param_grid, cv=5, \n",
    "                           return_train_score=True, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 21) #I picked 21 because I'm 21\n",
    "\n",
    "model.fit(X_pca, y_train)\n",
    "model.score(X_test_p, y_test)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "Let's see how RF changes our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': np.arange(10)+1}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=5, return_train_score=True, \n",
    "                           verbose=1)\n",
    "grid_search.fit(X_pca, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best model: {}\".format(grid_search.best_estimator_))\n",
    "print(classification_report(y_test, model.predict(X_test_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
